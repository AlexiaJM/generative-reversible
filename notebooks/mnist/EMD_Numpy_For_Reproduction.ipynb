{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/schirrmr/\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 4.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "seaborn.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# add the repo itself\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "## from  http://deeplearning.net/data/mnist/mnist.pkl.gz I assume?\n",
    "train, val, test = pickle.load(gzip.open('data/mnist/mnist.pkl.gz'), encoding='bytes')\n",
    "\n",
    "X_train, y_train = train\n",
    "X_val, y_val = val\n",
    "\n",
    "X_train_topo = X_train.reshape(X_train.shape[0], 1, 28,28)\n",
    "X_val_topo = X_val.reshape(X_val.shape[0], 1, 28,28)\n",
    "from numpy.random import RandomState\n",
    "#X_train_topo = np.pad(X_train_topo,((0,0),(0,0),(2,2),(2,2)), 'constant')\n",
    "#X_val_topo = np.pad(X_val_topo,((0,0),(0,0),(2,2),(2,2)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.revnet import ReversibleBlock\n",
    "import torch.nn as nn\n",
    "def rev_block(n_chans, n_intermediate_chans):\n",
    "    c = n_chans // 2\n",
    "    n_i_c = n_intermediate_chans\n",
    "    return ReversibleBlock(\n",
    "        nn.Sequential(\n",
    "            (nn.Linear(c, n_i_c,)),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(n_i_c, c,)),\n",
    "        nn.Sequential(\n",
    "            (nn.Linear(c, n_i_c,)),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(n_i_c, c,)))\n",
    "\n",
    "def plot_sorted_examples(sorted_examples, cmap=cm.Greys_r, vmin=0,vmax=1):\n",
    "    fig, axes = plt.subplots(2,10, figsize=(20,5))\n",
    "    for ax, im in zip(axes.flatten(), sorted_examples.squeeze()):\n",
    "        ax.imshow(im, vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (y_train == 0) | (y_train == 1)\n",
    "x = X_train_topo[mask]#[:1000]\n",
    "y = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.iterator import GenerativeIterator\n",
    "from reversible.revnet import SubsampleSplitter, ViewAs\n",
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "import torch as th\n",
    "set_random_seeds(34093049, True)\n",
    "feature_model = th.nn.Sequential(\n",
    "    SubsampleSplitter(stride=2,checkerboard=True),\n",
    "    ViewAs((-1,4,14,14),(-1,4*14*14)),\n",
    "    rev_block(784,2000),\n",
    "    rev_block(784,2000),\n",
    "    rev_block(784,2000),)\n",
    "feature_model = feature_model.cuda()\n",
    "init_model_params(feature_model, 1)\n",
    "\n",
    "n_dims = int(np.prod(x.shape[1:]))\n",
    "n_clusters = int(len(np.unique(y)))\n",
    "means_per_dim = th.autograd.Variable(th.zeros(n_clusters,n_dims).cuda() * 1.0, requires_grad=True)\n",
    "stds_per_dim = th.autograd.Variable(th.ones(n_clusters,n_dims).cuda()  * 0.5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.sliced import sample_directions\n",
    "from reversible.util import np_to_var\n",
    "directions_adv = th.cat([sample_directions(n_dims, True,True),\n",
    "                         sample_directions(n_dims, True,True),\n",
    "                         sample_directions(n_dims, True,True),\n",
    "                        ],dim=0)\n",
    "directions_adv = th.autograd.Variable(directions_adv.data, requires_grad=True)\n",
    "\n",
    "inputs = np_to_var(x, dtype=np.float32).cuda()\n",
    "targets = np_to_var(np.array([y == 0, y == 1]).T, dtype=np.float32).cuda()\n",
    "\n",
    "from reversible.training import init_std_mean\n",
    "\n",
    "init_std_mean(feature_model, inputs, targets, means_per_dim, stds_per_dim,\n",
    "                 set_phase_interval=True)\n",
    "\n",
    "optimizer = th.optim.Adam([\n",
    "    {'params': list(feature_model.parameters()) + \n",
    "                       [means_per_dim, stds_per_dim],\n",
    "    'lr': 0.001},],\n",
    "{'params':[directions_adv,],\n",
    "    'lr': -0.001},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = GenerativeIterator(upsample_supervised=True, batch_size=10610//8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.sinkhorn import sinkhorn_to_gauss_dist\n",
    "from reversible.sliced import sliced_from_samples_for_gauss_dist\n",
    "from reversible.loss_util import hard_loss_per_cluster\n",
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.revnet import invert\n",
    "from reversible.ot_exact import ot_emd_loss\n",
    "\n",
    "def reconstruct_loss(o,m,s):\n",
    "    o = o[:len(o)//2]\n",
    "    inputs = invert(feature_model, o)\n",
    "    o_perturbed = o + get_gauss_samples(len(o), m.detach()*0, s.detach() * 0 + 0.01)\n",
    "    inputs_perturbed = invert(feature_model, o_perturbed)\n",
    "    diffs = inputs - inputs_perturbed\n",
    "    loss = th.mean(diffs * diffs)\n",
    "    loss += th.mean(th.abs(diffs))\n",
    "    return loss\n",
    "\n",
    "hard_loss_fn = lambda o,m,s : (ot_emd_loss(o,m,s) +\n",
    "                              + 15 * sliced_from_samples_for_gauss_dist(o,m,s,n_dirs=4, adv_dirs=None)\n",
    "                              + 15 * reconstruct_loss(o,m,s))\n",
    "loss_fn = lambda o,d,t,m,s: hard_loss_per_cluster(o,t,m,s, hard_loss_fn)\n",
    "\n",
    "loss_fn_adv = None # no adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_one_batch(iterator, feature_model, loss_fn, means_per_dim, stds_per_dim,\n",
    "                   optimizer):\n",
    "    b = iterator.get_batches(inputs, targets, None, None)\n",
    "    b_X, b_y = b.__next__()\n",
    "    outs = feature_model(b_X)\n",
    "    loss = loss_fn(outs, None, b_y, means_per_dim, stds_per_dim)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = var_to_np(loss)[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batches_per_dataset = len([b for b in iterator.get_batches(inputs, targets, None, None)])\n",
    "n_critic_updates = 0\n",
    "n_updates_per_epoch = int(np.ceil(n_batches_per_dataset / (n_critic_updates + 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reversible.util import var_to_np\n",
    "from reversible.revnet import get_inputs_from_reverted_samples\n",
    "\n",
    "rng = RandomState(1)\n",
    "epochs_dataframe = pd.DataFrame()\n",
    "for i_epoch in range(100001):\n",
    "    feature_model.train()\n",
    "    for i_update in range(n_updates_per_epoch):\n",
    "        if i_update % (n_critic_updates + 1) == n_critic_updates:\n",
    "            # now run generator\n",
    "            loss = train_one_batch(iterator, feature_model, loss_fn, means_per_dim, stds_per_dim, optimizer)\n",
    "            stds_per_dim.data.clamp_(min=0)\n",
    "        else:\n",
    "            loss = train_one_batch(iterator, feature_model, loss_fn_adv, means_per_dim, stds_per_dim, optimizer_adv)\n",
    "            stds_per_dim.data.clamp_(min=0) # should not be necessary...\n",
    "    feature_model.eval()\n",
    "    epochs_dataframe = epochs_dataframe.append({\n",
    "        'total_loss': np.mean(loss),\n",
    "    },\n",
    "        ignore_index=True)\n",
    "    if i_epoch % 10 == 0:\n",
    "        display(epochs_dataframe.iloc[-1:])\n",
    "    if i_epoch % 100 == 0:\n",
    "        \n",
    "        all_outs = feature_model(inputs)\n",
    "        all_outs = var_to_np(all_outs).squeeze()\n",
    "        \n",
    "        for i_cluster in range(2):\n",
    "            fig = plt.figure()\n",
    "            plt.plot(var_to_np(stds_per_dim[i_cluster]))\n",
    "            plt.plot(np.std(all_outs[y == i_cluster], axis=0))\n",
    "            plt.legend(('Distribution', 'Outputs'))\n",
    "            plt.title(\"Stds of dimensions in gaussian and in actual outputs\", fontsize=18)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "        \n",
    "        for i_cluster in range(2):\n",
    "            rec_examples, _ = get_inputs_from_reverted_samples(\n",
    "                 15, means_per_dim[i_cluster:i_cluster+1], stds_per_dim[i_cluster:i_cluster+1],\n",
    "                np_to_var([1,]), feature_model,\n",
    "                to_4d=False)\n",
    "\n",
    "            fig, axes = plt.subplots(3,5, figsize=(20,9))\n",
    "\n",
    "            for i_example, ax in enumerate(axes.flatten()):\n",
    "                ax.imshow(rec_examples[i_example].squeeze(), vmin=0, vmax=1, cmap=cm.Greys)\n",
    "            fig.suptitle(\"Reverted examples using gaussian mean/std\", fontsize=18)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "        \n",
    "        for i_cluster in range(len(means_per_dim)):\n",
    "            mean =  np_to_var(np.mean(all_outs[y == i_cluster], axis=0, keepdims=True), dtype=np.float32).cuda()\n",
    "            std = np_to_var(np.std(all_outs[y == i_cluster], axis=0, keepdims=True), dtype=np.float32).cuda()\n",
    "            rec_examples, _ = get_inputs_from_reverted_samples(\n",
    "                 15, mean, std,\n",
    "                np_to_var([1,]), feature_model,\n",
    "                to_4d=False)\n",
    "\n",
    "            fig, axes = plt.subplots(3,5, figsize=(20,9))\n",
    "\n",
    "            for i_example, ax in enumerate(axes.flatten()):\n",
    "                ax.imshow(rec_examples[i_example].squeeze(), vmin=0, vmax=1, cmap=cm.Greys)\n",
    "            fig.suptitle(\"Reverted examples using mean/std of outputs\", fontsize=18)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "        \n",
    "        for i_cluster in range(2):\n",
    "            stds = np.std(all_outs[y == i_cluster], axis=0)\n",
    "            sorted_stds = np.argsort(stds)[::-1]\n",
    "            for i_large_std in sorted_stds[:3]:\n",
    "                stds_cloned = stds_per_dim.clone()\n",
    "                stds_cloned = stds_cloned * 0\n",
    "                stds_cloned[i_cluster,i_large_std] = float(stds[i_large_std])\n",
    "                rec_examples, gauss_samples = get_inputs_from_reverted_samples(\n",
    "                    1000, means_per_dim[i_cluster:i_cluster+1],\n",
    "                    stds_cloned[i_cluster:i_cluster+1], np_to_var([1]), feature_model, to_4d=False)\n",
    "                i_sort = np.argsort(var_to_np(gauss_samples)[:, i_large_std])\n",
    "                sorted_examples = rec_examples[i_sort]\n",
    "                sorted_examples = sorted_examples[::1000//20]\n",
    "                fig = plot_sorted_examples(sorted_examples)\n",
    "                fig.suptitle(\"Dimension {:d}\".format(i_large_std), fontsize=16)\n",
    "                display(fig)\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.training import select_outs_from_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = feature_model(inputs[:800])\n",
    "outs = select_outs_from_targets(outs, targets[:800], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sinkhorn_to_gauss_dist(outs,mean,std, epsilon=1e-1, stop_threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emd_loss(outs,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_dataframe.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outs = feature_model(inputs)\n",
    "all_outs = var_to_np(all_outs).squeeze()\n",
    "\n",
    "for i_cluster in range(2):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(var_to_np(stds_per_dim[i_cluster]))\n",
    "    plt.plot(np.std(all_outs[y == i_cluster], axis=0))\n",
    "    plt.legend(('Distribution', 'Outputs'))\n",
    "    plt.title(\"Stds of dimensions in gaussian and in actual outputs\", fontsize=18)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i_cluster in range(2):\n",
    "    rec_examples, _ = get_inputs_from_reverted_samples(\n",
    "         15, means_per_dim[i_cluster:i_cluster+1], stds_per_dim[i_cluster:i_cluster+1],\n",
    "        np_to_var([1,]), feature_model,\n",
    "        to_4d=False)\n",
    "\n",
    "    fig, axes = plt.subplots(3,5, figsize=(20,9))\n",
    "\n",
    "    for i_example, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(rec_examples[i_example].squeeze(), vmin=0, vmax=1, cmap=cm.Greys)\n",
    "    fig.suptitle(\"Reverted examples using gaussian mean/std\", fontsize=18)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i_cluster in range(len(means_per_dim)):\n",
    "    mean =  np_to_var(np.mean(all_outs[y == i_cluster], axis=0, keepdims=True), dtype=np.float32).cuda()\n",
    "    std = np_to_var(np.std(all_outs[y == i_cluster], axis=0, keepdims=True), dtype=np.float32).cuda()\n",
    "    rec_examples, _ = get_inputs_from_reverted_samples(\n",
    "         15, mean, std,\n",
    "        np_to_var([1,]), feature_model,\n",
    "        to_4d=False)\n",
    "\n",
    "    fig, axes = plt.subplots(3,5, figsize=(20,9))\n",
    "\n",
    "    for i_example, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(rec_examples[i_example].squeeze(), vmin=0, vmax=1, cmap=cm.Greys)\n",
    "    fig.suptitle(\"Reverted examples using mean/std of outputs\", fontsize=18)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i_cluster in range(2):\n",
    "    stds = np.std(all_outs[y == i_cluster], axis=0)\n",
    "    sorted_stds = np.argsort(stds)[::-1]\n",
    "    for i_large_std in sorted_stds[:3]:\n",
    "        stds_cloned = stds_per_dim.clone()\n",
    "        stds_cloned = stds_cloned * 0\n",
    "        stds_cloned[i_cluster,i_large_std] = float(stds[i_large_std])\n",
    "        rec_examples, gauss_samples = get_inputs_from_reverted_samples(\n",
    "            1000, means_per_dim[i_cluster:i_cluster+1],\n",
    "            stds_cloned[i_cluster:i_cluster+1], np_to_var([1]), feature_model, to_4d=False)\n",
    "        i_sort = np.argsort(var_to_np(gauss_samples)[:, i_large_std])\n",
    "        sorted_examples = rec_examples[i_sort]\n",
    "        sorted_examples = sorted_examples[::1000//20]\n",
    "        fig = plot_sorted_examples(sorted_examples)\n",
    "        fig.suptitle(\"Dimension {:d}\".format(i_large_std), fontsize=16)\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outs = feature_model(inputs)\n",
    "all_outs = var_to_np(all_outs).squeeze()\n",
    "\n",
    "for i_cluster in range(2):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(var_to_np(stds_per_dim[i_cluster]))\n",
    "    plt.plot(np.std(all_outs[y == i_cluster], axis=0))\n",
    "    plt.legend(('Distribution', 'Outputs'))\n",
    "    plt.title(\"Stds of dimensions in gaussian and in actual outputs\", fontsize=18)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i_cluster in range(2):\n",
    "    rec_examples, _ = get_inputs_from_reverted_samples(\n",
    "         len(inputs), means_per_dim[i_cluster:i_cluster+1], stds_per_dim[i_cluster:i_cluster+1],\n",
    "        np_to_var([1,]), feature_model,\n",
    "        to_4d=False)\n",
    "\n",
    "    fig, axes = plt.subplots(3,5, figsize=(20,9))\n",
    "\n",
    "    for i_example, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(rec_examples[i_example].squeeze(), vmin=0, vmax=1, cmap=cm.Greys)\n",
    "    fig.suptitle(\"Reverted examples using gaussian mean/std\", fontsize=18)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i_cluster in range(len(means_per_dim)):\n",
    "    mean =  np_to_var(np.mean(all_outs[y == i_cluster], axis=0, keepdims=True), dtype=np.float32).cuda()\n",
    "    std = np_to_var(np.std(all_outs[y == i_cluster], axis=0, keepdims=True), dtype=np.float32).cuda()\n",
    "    rec_examples, _ = get_inputs_from_reverted_samples(\n",
    "         len(inputs), mean, std,\n",
    "        np_to_var([1,]), feature_model,\n",
    "        to_4d=False)\n",
    "\n",
    "    fig, axes = plt.subplots(3,5, figsize=(20,9))\n",
    "\n",
    "    for i_example, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(rec_examples[i_example].squeeze(), vmin=0, vmax=1, cmap=cm.Greys)\n",
    "    fig.suptitle(\"Reverted examples using mean/std of outputs\", fontsize=18)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i_cluster in range(2):\n",
    "    stds = np.std(all_outs[y == i_cluster], axis=0)\n",
    "    sorted_stds = np.argsort(stds)[::-1]\n",
    "    for i_large_std in sorted_stds[:3]:\n",
    "        stds_cloned = stds_per_dim.clone()\n",
    "        stds_cloned = stds_cloned * 0\n",
    "        stds_cloned[i_cluster,i_large_std] = float(stds[i_large_std])\n",
    "        rec_examples, gauss_samples = get_inputs_from_reverted_samples(\n",
    "            1000, means_per_dim[i_cluster:i_cluster+1],\n",
    "            stds_cloned[i_cluster:i_cluster+1], np_to_var([1]), feature_model, to_4d=False)\n",
    "        i_sort = np.argsort(var_to_np(gauss_samples)[:, i_large_std])\n",
    "        sorted_examples = rec_examples[i_sort]\n",
    "        sorted_examples = sorted_examples[::1000//20]\n",
    "        fig = plot_sorted_examples(sorted_examples)\n",
    "        fig.suptitle(\"Dimension {:d}\".format(i_large_std), fontsize=16)\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discrete sag\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
