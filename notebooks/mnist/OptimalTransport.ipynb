{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 4.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "seaborn.set_palette('colorblind')\n",
    "\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## from  http://deeplearning.net/data/mnist/mnist.pkl.gz I assume?\n",
    "mnist_folder = 'data/mnist/mnist.pkl.gz'\n",
    "# For saving the model\n",
    "model_save_folder = '/data//schirrmr/schirrmr/reversible-icml/models/mnist/OptimalTransportPerClassClampedStd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "train, val, test = pickle.load(gzip.open(mnist_folder), encoding='bytes')\n",
    "\n",
    "X_train, y_train = train\n",
    "X_val, y_val = val\n",
    "\n",
    "X_train_topo = X_train.reshape(X_train.shape[0], 1, 28,28)\n",
    "X_val_topo = X_val.reshape(X_val.shape[0], 1, 28,28)\n",
    "from numpy.random import RandomState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = y_train < 10 # all, can use this to only take a subset of classes\n",
    "x = X_train_topo[mask]#[:1000]\n",
    "y = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "import torch as th\n",
    "from reversible.models import create_MNIST_model\n",
    "th.backends.cudnn.benchmark = True\n",
    "set_random_seeds(34093049, True)\n",
    "feature_model = create_MNIST_model()\n",
    "\n",
    "feature_model = feature_model.cuda()\n",
    "init_model_params(feature_model, 1)\n",
    "\n",
    "n_dims = 1024#int(np.prod(x.shape[1:])) \n",
    "n_clusters = int(len(np.unique(y)))\n",
    "\n",
    "# will be initialized properly later\n",
    "means_per_cluster = [th.autograd.Variable(th.zeros(n_dims).cuda(), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "stds_per_cluster = [th.autograd.Variable(th.ones(n_dims).cuda(), requires_grad=True)\n",
    "                    for _ in range(n_clusters)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.training import hard_init_std_mean\n",
    "from reversible.util import np_to_var\n",
    "\n",
    "inputs = np_to_var(x, dtype=np.float32).cuda()\n",
    "targets = np_to_var(np.array([y == i for i in range(len(np.unique(y)))]).T, dtype=np.float32).cuda()\n",
    "\n",
    "\n",
    "hard_init_std_mean(means_per_cluster, stds_per_cluster, feature_model, inputs[:10000], targets[:10000], )\n",
    "\n",
    "optimizer = th.optim.Adam([\n",
    "    {'params': list(feature_model.parameters()) + \n",
    "     means_per_cluster + stds_per_cluster,\n",
    "    'lr': 0.001},],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.iterators import BalancedBatchSizeIterator\n",
    "\n",
    "batch_size = 650\n",
    "iterator = BalancedBatchSizeIterator(batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.revnet import invert\n",
    "from reversible.gaussian import get_gauss_samples\n",
    "def reconstruct_loss(feature_model, inputs,outputs,):\n",
    "    inputs = invert(feature_model, outputs)\n",
    "    perturbation = get_gauss_samples(\n",
    "        len(outputs), th.zeros_like(outputs[0]).detach(), th.ones_like(outputs[0].detach()) * 0.01)\n",
    "    o_perturbed = outputs + perturbation\n",
    "    inputs_perturbed = invert(feature_model, o_perturbed)\n",
    "    diffs = inputs - inputs_perturbed\n",
    "    loss = th.mean(diffs * diffs)\n",
    "    loss += th.mean(th.abs(diffs))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ot\n",
    "from reversible.util import ensure_on_same_device, np_to_var, var_to_np\n",
    "def ot_euclidean_loss(outs, mean, std):\n",
    "    gauss_samples = get_gauss_samples(len(outs), mean, std)\n",
    "\n",
    "    diffs = outs.unsqueeze(1) - gauss_samples.unsqueeze(0)\n",
    "    del gauss_samples\n",
    "    diffs = th.sqrt(th.clamp(th.sum(diffs * diffs, dim=2), min=1e-6))\n",
    "\n",
    "    transport_mat = ot.emd([],[], var_to_np(diffs))\n",
    "    # sometimes weird low values, try to prevent them\n",
    "    transport_mat = transport_mat * (transport_mat > (1.0/(diffs.numel())))\n",
    "\n",
    "    transport_mat = np_to_var(transport_mat, dtype=np.float32)\n",
    "    diffs, transport_mat = ensure_on_same_device(diffs, transport_mat)\n",
    "    loss = th.sum(transport_mat * diffs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train_one_epoch():\n",
    "    start_time = time.time()\n",
    "    b_gens = [iterator.get_batches(inputs[targets[:,i_cluster] == 1],\n",
    "                                  targets[targets[:,i_cluster] == 1], shuffle=True)\n",
    "                for i_cluster in range(len(means_per_cluster))]\n",
    "\n",
    "    more_batches = True\n",
    "    rec_losses = []\n",
    "    ot_losses = []\n",
    "    losses = []\n",
    "    while more_batches:\n",
    "        optimizer.zero_grad()\n",
    "        for i_cluster in range(len(b_gens)):\n",
    "            b_gen = b_gens[i_cluster]\n",
    "            try:\n",
    "                b_X, b_y = next(b_gen)\n",
    "                outs = feature_model(b_X)\n",
    "                rec_loss = reconstruct_loss(feature_model, b_X, outs,)\n",
    "                ot_loss = ot_euclidean_loss(outs, means_per_cluster[i_cluster], stds_per_cluster[i_cluster])\n",
    "                loss = rec_loss * 15 + ot_loss\n",
    "                loss.backward()\n",
    "                rec_losses.append(var_to_np(rec_loss))\n",
    "                ot_losses.append(var_to_np(ot_loss))\n",
    "                losses.append(var_to_np(loss))\n",
    "            except StopIteration:\n",
    "                more_batches = False\n",
    "        optimizer.step()\n",
    "        for i_cluster in range(len(stds_per_cluster)):\n",
    "            stds_per_cluster[i_cluster].data.clamp_(min=0)\n",
    "            runtime = time.time() - start_time\n",
    "    return {'rec_loss': np.mean(rec_losses),\n",
    "           'ot_losses': np.mean(ot_losses),\n",
    "           'loss': np.mean(losses),\n",
    "           'runtime': runtime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "epochs_dataframe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import var_to_np\n",
    "rng = RandomState(1)\n",
    "for i_epoch in range(100001):\n",
    "    feature_model.train()\n",
    "    result = train_one_epoch()\n",
    "    feature_model.eval()\n",
    "    epochs_dataframe = epochs_dataframe.append(result, ignore_index=True)\n",
    "    if i_epoch % 10 == 0:\n",
    "        display(epochs_dataframe.iloc[-1:])\n",
    "    if i_epoch % 10 == 0:\n",
    "        \n",
    "        all_outs = feature_model(inputs[:5000])\n",
    "        all_outs = var_to_np(all_outs).squeeze()\n",
    "        \n",
    "        for i_cluster in range(len(means_per_cluster)):\n",
    "            fig = plt.figure()\n",
    "            plt.plot(var_to_np(stds_per_cluster[i_cluster]))\n",
    "            plt.plot(np.std(all_outs[y[:5000] == i_cluster], axis=0))\n",
    "            plt.legend(('Distribution', 'Outputs'))\n",
    "            plt.title(\"Stds of dimensions in gaussian and in actual outputs\", fontsize=18)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "        for i_class in range(len(means_per_cluster)):\n",
    "            samples = get_gauss_samples(3*8, means_per_cluster[i_class], stds_per_cluster[i_class],)\n",
    "\n",
    "            inverted = var_to_np(invert(feature_model, samples)).astype(np.float64)\n",
    "            inverted = inverted.reshape(3,8,28,28)\n",
    "            im = create_bw_image(inverted).resize((4*100,int(1.5*100)))\n",
    "            display(im)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i_cluster in range(len(means_per_cluster)):\n",
    "            mean = means_per_cluster[i_cluster]\n",
    "            std = stds_per_cluster[i_cluster]\n",
    "            i_feature_a, i_feature_b = th.sort(std)[1][-2:]\n",
    "            feature_a_values = th.linspace(float(mean[i_feature_a].data - 2 * std[i_feature_a].data),\n",
    "                                           float(mean[i_feature_a].data + 2 * std[i_feature_a].data), 8)\n",
    "            feature_b_values = th.linspace(float(mean[i_feature_b].data - 2 * std[i_feature_b].data),\n",
    "                                           float(mean[i_feature_b].data + 2 * std[i_feature_b].data), 8)\n",
    "\n",
    "            image_grid = np.zeros((len(feature_a_values), len(feature_b_values), 28,28))\n",
    "\n",
    "            for i_f_a_val, f_a_val in enumerate(feature_a_values):\n",
    "                for i_f_b_val, f_b_val in enumerate(feature_b_values):\n",
    "                    this_out = mean.clone()\n",
    "                    this_out.data[i_feature_a.data] = f_a_val\n",
    "                    this_out.data[i_feature_b.data] = f_b_val\n",
    "                    inverted = var_to_np(invert(feature_model, this_out.unsqueeze(0))[0]).squeeze()\n",
    "\n",
    "                    image_grid[i_f_a_val, i_f_b_val] = np.copy(inverted)\n",
    "            im = create_bw_image(image_grid).resize((4*100,4*100))\n",
    "            display(im)\n",
    "    if i_epoch % 30 == 0:\n",
    "        folder =  os.path.join(model_save_folder, str(len(epochs_dataframe)))\n",
    "        os.makedirs(folder, exist_ok=False)\n",
    "        epochs_dataframe.to_csv(os.path.join(folder, 'epochs_df.csv'))\n",
    "        th.save(optimizer.state_dict(), os.path.join(folder, 'optim_dict.pkl'))\n",
    "        th.save(feature_model.state_dict(), os.path.join(folder, 'model_dict.pkl'))\n",
    "        th.save(means_per_cluster, os.path.join(folder, 'means.pkl'))\n",
    "        th.save(stds_per_cluster, os.path.join(folder, 'stds.pkl'))\n",
    "        log.info(\"Saved to {:s}\".format(folder))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
